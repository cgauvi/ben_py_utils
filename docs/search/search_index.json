{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"General python functions meant to be reused in different projects This is the documentation for the ben_py_utils python module.","title":"Home"},{"location":"index.html#general-python-functions-meant-to-be-reused-in-different-projects","text":"This is the documentation for the ben_py_utils python module.","title":"General python functions meant to be reused in different projects"},{"location":"cache.html","text":"Cache_wrapper Semi fancy wrapper implemented as callable class that caches results to a parquet file. Can be used as such: @Cache_wrapper(path_cache='bla/blo.parquet') def foo(): pass Tries the following file formats in order and moves to next only in case of failure: 1) .parquet 2) extension considered in name (e.g. csv or geojson if path_cache = 'bla.csv') 3) if Geodf, alternative geoformat (either shp or geojson ) Source code in ben_py_utils/misc/cache.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 class Cache_wrapper : \"\"\"Semi fancy wrapper implemented as callable class that caches results to a parquet file. Can be used as such: ``` @Cache_wrapper(path_cache='bla/blo.parquet') def foo(): pass ``` Tries the following file formats in order and moves to next only in case of failure: 1) .parquet 2) extension considered in name (e.g. csv or geojson if path_cache = 'bla.csv') 3) if Geodf, alternative geoformat (either shp or geojson ) Attributes: path_cache (str), Default[None] Path of destination file with parquet extention pd_save_index (boolean), Default[False] Save pandas index? force_overwrite (boolean), Default[False] Run the function even the results have been cached \"\"\" def __init__ ( self , path_cache , pd_save_index = False , force_overwrite = False ): self . path_cache = path_cache self . pd_save_index = pd_save_index self . force_overwrite = force_overwrite # Make sure we save as parquet # Not the same interface with and without parquet - using a more general data format is good, but adds to mnay flows to the code path_pre , path_ext = splitext ( self . path_cache ) if path_ext != \".parquet\" : raise ValueError ( f \"Fatal error, extension is { path_ext } - should be .parquet \" ) def _read_existing_file ( self ) -> Union [ pd . DataFrame , gpd . GeoDataFrame ]: \"\"\" Try to read back an existing file from cache Returns: Union[pd.DataFrame, gpd.GeoDataFrame]: _description_ \"\"\" logger . info ( f 'Reading back { self . path_cache } ...' ) try : df_result = gpd . read_parquet ( self . path_cache ) except Exception as e : logger . warning ( f \"Fatal error trying to load back geo data from { self . path_cache } - { str ( e ) } - trying with pandas\" ) try : df_result = pd . read_parquet ( self . path_cache ) except Exception as e : raise e ( f \"Fatal error trying to load back NON geo data from { self . path_cache } - { str ( e ) } \" ) # Remove useless index if present and if we want to disregard indixes if 'Unnamed: 0' in df_result . columns and not self . pd_save_index : df_result = df_result . drop ( columns = { 'Unnamed: 0' }) return df_result def _create_new_file ( self , fun , * kws , ** kwargs ) -> Union [ pd . DataFrame , gpd . GeoDataFrame ] : \"\"\" Run fun(*kws, **kwargs) and cache the results Args: fun (_type_): function to run Returns: Union[pd.DataFrame, gpd.GeoDataFrame] : df created by fun + cached \"\"\" logger . info ( f 'Creating new { self . path_cache } ...' ) df_result = fun ( * kws , ** kwargs ) try : # Raw df_result . to_parquet ( self . path_cache , index = False ) except Exception : # Try converting to string first try : df_result . columns = df_result . columns . astype ( str ) df_result . to_parquet ( self . path_cache , engine = 'pyarrow' , index = False ) # Fail: try different paths depending on gpd or pd df except Exception as err : logger . error ( f 'Parquet file creation failed \\n { err } ' ) return df_result def __call__ ( self , fun ): def inner_wrapper ( * kws , ** kwargs ): if not isdir ( dirname ( self . path_cache )): makedirs ( dirname ( self . path_cache )) if isfile ( self . path_cache ) and not self . force_overwrite : df_result = self . _read_existing_file () else : df_result = self . _create_new_file ( fun , * kws , ** kwargs ) return df_result return inner_wrapper","title":"Cache"},{"location":"cache.html#ben_py_utils.misc.cache.Cache_wrapper","text":"Semi fancy wrapper implemented as callable class that caches results to a parquet file. Can be used as such: @Cache_wrapper(path_cache='bla/blo.parquet') def foo(): pass Tries the following file formats in order and moves to next only in case of failure: 1) .parquet 2) extension considered in name (e.g. csv or geojson if path_cache = 'bla.csv') 3) if Geodf, alternative geoformat (either shp or geojson ) Source code in ben_py_utils/misc/cache.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 class Cache_wrapper : \"\"\"Semi fancy wrapper implemented as callable class that caches results to a parquet file. Can be used as such: ``` @Cache_wrapper(path_cache='bla/blo.parquet') def foo(): pass ``` Tries the following file formats in order and moves to next only in case of failure: 1) .parquet 2) extension considered in name (e.g. csv or geojson if path_cache = 'bla.csv') 3) if Geodf, alternative geoformat (either shp or geojson ) Attributes: path_cache (str), Default[None] Path of destination file with parquet extention pd_save_index (boolean), Default[False] Save pandas index? force_overwrite (boolean), Default[False] Run the function even the results have been cached \"\"\" def __init__ ( self , path_cache , pd_save_index = False , force_overwrite = False ): self . path_cache = path_cache self . pd_save_index = pd_save_index self . force_overwrite = force_overwrite # Make sure we save as parquet # Not the same interface with and without parquet - using a more general data format is good, but adds to mnay flows to the code path_pre , path_ext = splitext ( self . path_cache ) if path_ext != \".parquet\" : raise ValueError ( f \"Fatal error, extension is { path_ext } - should be .parquet \" ) def _read_existing_file ( self ) -> Union [ pd . DataFrame , gpd . GeoDataFrame ]: \"\"\" Try to read back an existing file from cache Returns: Union[pd.DataFrame, gpd.GeoDataFrame]: _description_ \"\"\" logger . info ( f 'Reading back { self . path_cache } ...' ) try : df_result = gpd . read_parquet ( self . path_cache ) except Exception as e : logger . warning ( f \"Fatal error trying to load back geo data from { self . path_cache } - { str ( e ) } - trying with pandas\" ) try : df_result = pd . read_parquet ( self . path_cache ) except Exception as e : raise e ( f \"Fatal error trying to load back NON geo data from { self . path_cache } - { str ( e ) } \" ) # Remove useless index if present and if we want to disregard indixes if 'Unnamed: 0' in df_result . columns and not self . pd_save_index : df_result = df_result . drop ( columns = { 'Unnamed: 0' }) return df_result def _create_new_file ( self , fun , * kws , ** kwargs ) -> Union [ pd . DataFrame , gpd . GeoDataFrame ] : \"\"\" Run fun(*kws, **kwargs) and cache the results Args: fun (_type_): function to run Returns: Union[pd.DataFrame, gpd.GeoDataFrame] : df created by fun + cached \"\"\" logger . info ( f 'Creating new { self . path_cache } ...' ) df_result = fun ( * kws , ** kwargs ) try : # Raw df_result . to_parquet ( self . path_cache , index = False ) except Exception : # Try converting to string first try : df_result . columns = df_result . columns . astype ( str ) df_result . to_parquet ( self . path_cache , engine = 'pyarrow' , index = False ) # Fail: try different paths depending on gpd or pd df except Exception as err : logger . error ( f 'Parquet file creation failed \\n { err } ' ) return df_result def __call__ ( self , fun ): def inner_wrapper ( * kws , ** kwargs ): if not isdir ( dirname ( self . path_cache )): makedirs ( dirname ( self . path_cache )) if isfile ( self . path_cache ) and not self . force_overwrite : df_result = self . _read_existing_file () else : df_result = self . _create_new_file ( fun , * kws , ** kwargs ) return df_result return inner_wrapper","title":"Cache_wrapper"},{"location":"compose.html","text":"apply_n_times ( fun , n , * args , ** kws ) Apply a function n times Source code in ben_py_utils/misc/compose.py 16 17 18 19 20 21 22 def apply_n_times ( fun , n , * args , ** kws ): '''Apply a function n times ''' fun_power_n = [ fun for i in range ( n )] return composite_function ( * fun_power_n )( * args , ** kws ) #need to unpack fun_power_n, which is a list composite_function ( * func ) Compose a function https://www.geeksforgeeks.org/function-composition-in-python/#:~:text=Function%20composition%20is%20the%20way,second%20function%20and%20so%20on. Source code in ben_py_utils/misc/compose.py 7 8 9 10 11 12 13 14 def composite_function ( * func ): ''' Compose a function https://www.geeksforgeeks.org/function-composition-in-python/#:~:text=Function%20composition%20is%20the%20way,second%20function%20and%20so%20on. ''' def compose ( f , g ): return lambda x : f ( g ( x )) return reduce ( compose , func , lambda x : x ) move_up_n_time ( path , n ) Move up n times in a directory, starting at path Source code in ben_py_utils/misc/compose.py 24 25 26 27 28 29 30 31 32 33 def move_up_n_time ( path , n ): ''' Move up n times in a directory, starting at path ''' new_dir = apply_n_times ( dirname , n , path ) if new_dir == '/' : print ( 'Warning, moved up to the root' ) return new_dir","title":"Compose"},{"location":"compose.html#ben_py_utils.misc.compose.apply_n_times","text":"Apply a function n times Source code in ben_py_utils/misc/compose.py 16 17 18 19 20 21 22 def apply_n_times ( fun , n , * args , ** kws ): '''Apply a function n times ''' fun_power_n = [ fun for i in range ( n )] return composite_function ( * fun_power_n )( * args , ** kws ) #need to unpack fun_power_n, which is a list","title":"apply_n_times()"},{"location":"compose.html#ben_py_utils.misc.compose.composite_function","text":"Compose a function https://www.geeksforgeeks.org/function-composition-in-python/#:~:text=Function%20composition%20is%20the%20way,second%20function%20and%20so%20on. Source code in ben_py_utils/misc/compose.py 7 8 9 10 11 12 13 14 def composite_function ( * func ): ''' Compose a function https://www.geeksforgeeks.org/function-composition-in-python/#:~:text=Function%20composition%20is%20the%20way,second%20function%20and%20so%20on. ''' def compose ( f , g ): return lambda x : f ( g ( x )) return reduce ( compose , func , lambda x : x )","title":"composite_function()"},{"location":"compose.html#ben_py_utils.misc.compose.move_up_n_time","text":"Move up n times in a directory, starting at path Source code in ben_py_utils/misc/compose.py 24 25 26 27 28 29 30 31 32 33 def move_up_n_time ( path , n ): ''' Move up n times in a directory, starting at path ''' new_dir = apply_n_times ( dirname , n , path ) if new_dir == '/' : print ( 'Warning, moved up to the root' ) return new_dir","title":"move_up_n_time()"},{"location":"profiler.html","text":"time_function ( fun ) Basic decorator to time the execution of a function. Source code in ben_py_utils/misc/profiler.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def time_function ( fun ): \"\"\" Basic decorator to time the execution of a function. \"\"\" @wraps ( fun ) def inner_wrapper ( * kws , ** kwargs ): \"\"\" Basic decorator to time the execution of a function. Args: *kws, **kwargs Returns: result, time of execution (tuple): result of fun(*kws, **kwargs) + time to run \"\"\" start = time . time () results = fun ( * kws , ** kwargs ) end = time . time () return results , end - start return inner_wrapper","title":"Profiler"},{"location":"profiler.html#ben_py_utils.misc.profiler.time_function","text":"Basic decorator to time the execution of a function. Source code in ben_py_utils/misc/profiler.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def time_function ( fun ): \"\"\" Basic decorator to time the execution of a function. \"\"\" @wraps ( fun ) def inner_wrapper ( * kws , ** kwargs ): \"\"\" Basic decorator to time the execution of a function. Args: *kws, **kwargs Returns: result, time of execution (tuple): result of fun(*kws, **kwargs) + time to run \"\"\" start = time . time () results = fun ( * kws , ** kwargs ) end = time . time () return results , end - start return inner_wrapper","title":"time_function()"},{"location":"ssl.html","text":"no_ssl_verification () Context manager that turns off ssl verification temporarily. Example usage with no_ssl_verification(): pass Source code in ben_py_utils/misc/ssl.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @contextlib . contextmanager def no_ssl_verification (): \"\"\" Context manager that turns off ssl verification temporarily. Example usage with no_ssl_verification(): pass \"\"\" opened_adapters = set () def merge_environment_settings ( self , url , proxies , stream , verify , cert ): # Verification happens only once per connection so we need to close # all the opened adapters once we're done. Otherwise, the effects of # verify=False persist beyond the end of this context manager. opened_adapters . add ( self . get_adapter ( url )) settings = old_merge_environment_settings ( self , url , proxies , stream , verify , cert ) settings [ 'verify' ] = False return settings requests . Session . merge_environment_settings = merge_environment_settings try : with warnings . catch_warnings (): warnings . simplefilter ( 'ignore' , InsecureRequestWarning ) yield finally : requests . Session . merge_environment_settings = old_merge_environment_settings for adapter in opened_adapters : try : adapter . close () except : pass","title":"SSL"},{"location":"ssl.html#ben_py_utils.misc.ssl.no_ssl_verification","text":"Context manager that turns off ssl verification temporarily. Example usage with no_ssl_verification(): pass Source code in ben_py_utils/misc/ssl.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @contextlib . contextmanager def no_ssl_verification (): \"\"\" Context manager that turns off ssl verification temporarily. Example usage with no_ssl_verification(): pass \"\"\" opened_adapters = set () def merge_environment_settings ( self , url , proxies , stream , verify , cert ): # Verification happens only once per connection so we need to close # all the opened adapters once we're done. Otherwise, the effects of # verify=False persist beyond the end of this context manager. opened_adapters . add ( self . get_adapter ( url )) settings = old_merge_environment_settings ( self , url , proxies , stream , verify , cert ) settings [ 'verify' ] = False return settings requests . Session . merge_environment_settings = merge_environment_settings try : with warnings . catch_warnings (): warnings . simplefilter ( 'ignore' , InsecureRequestWarning ) yield finally : requests . Session . merge_environment_settings = old_merge_environment_settings for adapter in opened_adapters : try : adapter . close () except : pass","title":"no_ssl_verification()"}]}